---
about_this_resource_text: <h2 class="subhead">Summary</h2> <p>This video begins with
  observations of spontaneous processes from daily life and then connects the idea
  of spontaneity to entropy. Entropy is described as a measure of the number of possible
  ways energy can be distributed in a system of molecules. Students apply this description
  to understand the entropy change in a heat diffusion experiment.</p> <h2 class="subhead">Learning
  Objectives</h2> <p>After watching this video students will be able to:</p> <ul>     <li>Describe,
  at a basic level, the concept of a microstate.</li>     <li>Discuss what entropy
  measures in a conceptual way.</li> </ul><p>&nbsp;</p><p>Funding provided by the
  Singapore University of Technology and Design (SUTD)</p><p>Developed by the Teaching
  and Learning Laboratory (TLL) at MIT for SUTD</p><p>MIT &copy; 2012</p>
course_id: res-tll-004-stem-concept-videos-fall-2013
embedded_media:
- id: Video-iTunesU-MP4
  media_location: https://itunes.apple.com/us/itunes-u/entropy/id765926614?i=194533713
  parent_uid: dc339cdfe5746110705e7a382b8b5cc5
  title: Video-iTunes U-MP4
  type: Video
  uid: c0f56fc9acada38a505a7b2958d01847
- id: Video-InternetArchive-MP4
  media_location: http://www.archive.org/download/MITRES.TLL-004F13/MITRES_TLL-004F13_entropy_intro_300k.mp4
  parent_uid: dc339cdfe5746110705e7a382b8b5cc5
  title: Video-Internet Archive-MP4
  type: Video
  uid: 961dab5bd01b8bbfdf51d757b6daed5c
- id: Video-YouTube-Stream
  media_location: 870y6GUKbwc
  parent_uid: dc339cdfe5746110705e7a382b8b5cc5
  title: Video-YouTube-Stream
  type: Video
  uid: c0722c9618b6a49b4ac34c210f4dee46
- id: Thumbnail-YouTube-JPG
  media_location: https://img.youtube.com/vi/870y6GUKbwc/default.jpg
  parent_uid: dc339cdfe5746110705e7a382b8b5cc5
  title: Thumbnail-YouTube-JPG
  type: Thumbnail
  uid: 5d3158939f52419fb3ad2ff2822ce838
- id: 3Play-3PlayYouTubeid-MP4
  media_location: 870y6GUKbwc
  parent_uid: dc339cdfe5746110705e7a382b8b5cc5
  title: 3Play-3Play YouTube id
  type: 3Play
  uid: 9580097e08289e9d4b7a7f052d13befe
- id: 870y6GUKbwc.srt
  parent_uid: dc339cdfe5746110705e7a382b8b5cc5
  technical_location: https://ocw.mit.edu/resources/res-tll-004-stem-concept-videos-fall-2013/videos/governing-rules/entropy/870y6GUKbwc.srt
  title: 3play caption file
  type: null
  uid: bd4c44de26ff035b5a44c2f7f9e0070b
- id: 870y6GUKbwc.pdf
  parent_uid: dc339cdfe5746110705e7a382b8b5cc5
  technical_location: https://ocw.mit.edu/resources/res-tll-004-stem-concept-videos-fall-2013/videos/governing-rules/entropy/870y6GUKbwc.pdf
  title: 3play pdf file
  type: null
  uid: 832f857143dd44de83976cc28ee63011
- id: Caption-3Play YouTube id-SRT
  parent_uid: dc339cdfe5746110705e7a382b8b5cc5
  title: Caption-3Play YouTube id-SRT-English - US
  type: Caption
  uid: f47916187245c32e31ad20f5d91adbe7
- id: Transcript-3Play YouTube id-PDF
  parent_uid: dc339cdfe5746110705e7a382b8b5cc5
  title: Transcript-3Play YouTube id-PDF-English - US
  type: Transcript
  uid: 9abbef9673884279d9febbb8f0d7d52c
inline_embed_id: 61650882entropy56498580
layout: video
order_index: null
parent_uid: 5c800495c618099d48029286b0d45a90
related_resources_text: <p>Instructor Guide</p> <p><a href="./resolveuid/e6769deb59c187e94903f5f423f07c00"
  target="_blank">Entropy Instructor Guide (PDF)</a></p> <p>&nbsp;</p>
short_url: entropy
technical_location: https://ocw.mit.edu/resources/res-tll-004-stem-concept-videos-fall-2013/videos/governing-rules/entropy
template_type: Tabbed
title: Entropy
transcript: <p><span m='3520'>You have probably heard entropy defined or described
  as "disorder." The usual example</span> <span m='8460'>is that of a college dorm
  room, which, without regular tidying, becomes "messier" or "less</span> <span m='13280'>ordered"
  over time. Supposedly the entropy of the messy room is higher than that of the</span>
  <span m='18100'>tidy room. This analogy is easy to picture, but it's misleading.
  In this video, you'll</span> <span m='24340'>learn a more accurate description of
  entropy and understand how it relates to the concept</span> <span m='27380'>of spontaneity.</span>
  </p><p><span m='27550'>This video is part of the Governing Rules video series. A
  small number of rules describe</span> <span m='31880'>the physical and chemical
  interactions that are possible in our universe.</span> </p><p><span m='36040'>Hi.
  My name is John Lienhard and I am a professor in the Department of Mechanical Engineering</span>
  <span m='41390'>at MIT.</span> </p><p><span m='42660'>Today, I'm going to talk to
  you about entropy, a fascinating, but often confusing topic.</span> </p><p><span
  m='51180'>In order to understand the topic of this video, you should be familiar
  with the idea that</span> <span m='55520'>energy is quantized and the thermodynamic
  definition of a system and its surroundings.</span> </p><p><span m='62320'>After
  watching this video, you should be able to describe, at a basic level, the concept</span>
  <span m='66950'>of a microstate. You should also be able to discuss what entropy
  measures in a conceptual</span> <span m='71899'>way.</span> </p><p><span m='73240'>First,
  what do we mean by a spontaneous process? In thermodynamics, a spontaneous process
  is</span> <span m='80880'>one that will occur without any outside intervention given
  enough time.</span> </p><p><span m='85810'>In the world around us, many everyday
  events proceed in a particular manner. We would call</span> <span m='91279'>them
  spontaneous. You have observed spontaneous processes yourself, but because they
  seem</span> <span m='97020'>so natural, you may not have taken particular note of
  them.</span> </p><p><span m='101450'>For example, think of an inflated balloon that
  hasn't been tied and is simply pinched</span> <span m='105630'>between someone's
  fingers. Once the person releases the balloon, what is going to happen?</span> </p><p><span
  m='113729'>Experience tells us that the gas inside the balloon will rapidly escape
  from the opening,</span> <span m='118840'>moving from high pressure to low pressure.
  This will propel the balloon through the air,</span> <span m='123639'>until finally,
  we are left with a deflated balloon. The gas that was once in the balloon</span>
  <span m='128910'>is now dispersed throughout the surroundings.</span> </p><p><span
  m='132970'>You have probably also seen food coloring or hydrophilic dye dropped
  into water. What</span> <span m='138800'>happens? From experience, you may know
  that the dye disperses.</span> </p><p><span m='145390'>You may also have had some
  experience removing hot pans from the stovetop. While they come</span> <span m='150730'>off
  of the stovetop hot, we know they will eventually cool. Here, we see a liquid crystal</span>
  <span m='157020'>in the pan change color, first as the pan is heated, and then again,
  as the pan cools.</span> </p><p><span m='163640'>Experience tells us in which direction
  these everyday events will proceed. But what about</span> <span m='167829'>processes
  with which we don't have experience?</span> </p><p><span m='171470'>For example,
  it would be nice if we had a way of knowing whether or not a given chemical</span>
  <span m='176120'>reaction will happen at given conditions.</span> </p><p><span m='179940'>The
  2nd law of thermodynamics can help us with this.</span> </p><p><span m='184300'>The
  2nd law of thermodynamics states that during any spontaneous process, the total</span>
  <span m='189900'>entropy change of a system and its surroundings is positive. In
  other words, the entropy of</span> <span m='195990'>the "universe," that is, the
  system plus surroundings, can only increase.</span> </p><p><span m='202180'>But
  what is entropy? Is entropy a magical force that overturns your furniture and creates</span>
  <span m='207290'>havoc in your office or home? No.</span> </p><p><span m='210600'>Entropy
  is a measure of the number of possible ways energy can be distributed in a system</span>
  <span m='214020'>of molecules. Molecules in a system at equilibrium have the same
  average energy. However, at</span> <span m='220840'>a given instant in time, it
  is highly unlikely that all of the molecules have the same exact</span> <span m='226069'>energy.</span>
  </p><p><span m='228350'>Molecules in a system are constantly interacting and transferring
  energy amongst each other.</span> </p><p><span m='233319'>As a result, one molecule
  may have a certain amount of energy at one instant and at the</span> <span m='238360'>next;
  it could have more or less. Depending on the energy the molecule has, it will be</span>
  <span m='243640'>able to access different energy levels.</span> </p><p><span m='248150'>The
  total energy of the system, determines what energy levels will be accessible to
  the</span> <span m='251900'>molecules. Higher energy levels will not be accessible
  because the energy required to</span> <span m='257289'>reach them is not available.</span>
  </p><p><span m='261189'>So when we say that entropy is a measure of the number of
  possible ways energy can be</span> <span m='265099'>distributed in a system of molecules,
  we have to account for all of the possible combinations.</span> </p><p><span m='271249'>And
  the way we do that is by considering the microstates available to the molecules
  in</span> <span m='275580'>the system. Let's use an analogy to understand the term</span>
  <span m='280460'>"microstate".</span> </p><p><span m='281680'>Let's say that you
  have two dice. What are all of the possible sums for a pair of dice?</span> </p><p><span
  m='288069'>Pause the video here and take a moment to jot them down.</span> </p><p><span
  m='295439'>Okay, you should have a list that looks something like this. We would
  call these sums possible</span> <span m='302080'>macrostates of our system -- the
  macrostate doesn't tell us what each individual die reads</span> <span m='308199'>when
  we roll them, just the total, or "macroscopic view" if you will.</span> </p><p><span
  m='313569'>What are all of the possible dice combinations that will produce each
  of those sums? For</span> <span m='318300'>example, we can produce the sum of three
  by rolling a one on the first die and a two on</span> <span m='323240'>the 2nd die.
  Or, we can roll a 2 on the first die and a one on the 2nd die. So there are</span>
  <span m='328900'>two combinations that will produce the sum of 3.</span> </p><p><span
  m='332558'>The dice combinations that produce the remaining sums are shown here.</span>
  </p><p><span m='337219'>We would call each of these combinations "microstates" that
  correspond to each macrostate. The microstate</span> <span m='343759'>gives us information
  about the individual conditions of each die.</span> </p><p><span m='347669'>We see
  that the most likely macrostate, a sum of 7, has the greatest number of possible</span>
  <span m='352669'>microstates.</span> </p><p><span m='353139'>Do you think that the
  entropy change for the system (the cold bar) was positive, negative,</span> <span
  m='357849'>or equal to zero?</span> </p><p><span m='358969'>Please pause the video
  here and discuss your reasoning with a classmate.</span> </p><p><span m='365189'>Let's
  start with the system first. The transfer of energy to the cold bar will allow the
  molecules</span> <span m='403339'>in the cold bar to access new energy levels that
  they could not reach before, increasing</span> <span m='514229'>the number of possible
  microstates for that system. So we would suspect that the entropy</span> <span m='520309'>change
  for the system is positive.</span> </p><p><span m='523179'>But what about the surroundings?</span>
  </p><p><span m='525620'>The total entropy of a system and its surroundings has to
  increase if the process is spontaneous.</span> </p><p><span m='532140'>Let's use
  a very simplified diagram to think about the heat diffusion demo. We have two</span>
  <span m='537200'>bars made of the same material. One bar is hot and one is cold.
  We'll look at 4 atoms</span> <span m='544140'>making up each bar. The hot bar has
  more energy than the cold bar -- its atoms are moving</span> <span m='550490'>more
  than the atoms in the cold bar, which seem barely to move.</span> </p><p><span m='554640'>Now,
  before we put the cold bar in contact with the hot bar, let's think about each bar</span>
  <span m='559890'>separately. In our simplified drawing of the cold bar, let's say
  that three of the atoms</span> <span m='565100'>have no energy and one atom has
  one quantum of energy and is at a slightly higher energy</span> <span m='570520'>level,
  symbolized by the set of curved lines representing its motion. How many different</span>
  <span m='575930'>microstates can this system exhibit? If we think about the different
  ways we can</span> <span m='580660'>distribute the quantum of energy amongst the
  4 atoms, we see that there are 4 possible</span> <span m='585890'>microstates. If
  we do the same for our hot bar, where we</span> <span m='591010'>have 5 quanta of
  energy that can be distributed in a variety of ways amongst the 4 atoms,</span>
  <span m='596560'>we use some math to see that there are 56 possible microstates.</span>
  </p><p><span m='602360'>When we brought the two bars in contact in our demonstration,
  we saw that they reached</span> <span m='606570'>thermal equilibrium. Here, in our
  simplified example, we will bring</span> <span m='611650'>the cold bar (defined
  as our system) and the hot bar (defined as our surroundings) together</span> <span
  m='617780'>and divide the 6 quanta of energy equally between the two. The first
  law of thermodynamics</span> <span m='623460'>tells us that the total of 6 quanta
  will be conserved.</span> </p><p><span m='627520'>Now, how many microstates are
  now possible in each bar?</span> </p><p><span m='635250'>As you might have expected,
  the number of possible microstates in what was originally</span> <span m='639880'>our
  hot bar decreased, and the number of possible microstates in what was originally
  our cold</span> <span m='644930'>bar increased. Let's see what this means for our
  total entropy</span> <span m='648400'>change. We will use a relationship for entropy
  that was derived by Ludwig Boltzmann. It states</span> <span m='656020'>that entropy
  is equal to a constant, called the Boltzmann constant, times the natural</span>
  <span m='660810'>log of the number of microstates.</span> </p><p><span m='663720'>When
  calculating entropy change, whether it be for the system or surroundings, delta
  S</span> <span m='669040'>would be equal to Boltzmann's constant times the natural
  log of the ratio of the final</span> <span m='675080'>number of microstates to the
  initial number of microstates.</span> </p><p><span m='679630'>The entropy change
  in our cold bar was positive while the entropy change in our hot bar was</span>
  <span m='684550'>negative. But remember, it's the total entropy change that matters.
  We see that our total</span> <span m='690970'>entropy change for this process is
  positive. The spontaneous transfer of heat from our</span> <span m='696080'>hot
  bar to our cold bar is consistent with the 2nd law of thermodynamics.</span> </p><p><span
  m='702690'>If you did a similar calculation for the reverse process, that of heat
  transferring from the</span> <span m='707240'>cold bar to the hot bar, the total
  entropy change would be negative indicating that it</span> <span m='712130'>is not
  spontaneous. As we hinted earlier and as you may have guessed</span> <span m='717110'>by
  our very simplified scenario, calculating the number of microstates in a real system</span>
  <span m='722240'>can be very challenging. Generally speaking, you will be calculating
  entropy in terms of</span> <span m='727940'>measurable macroscopic quantities such
  as heat capacity or enthalpy of phase change.</span> </p><p><span m='734740'>However,
  having a qualitative understanding of the physical meaning of entropy will help</span>
  <span m='739940'>you properly interpret the entropy changes caused by various processes.</span>
  </p><p><span m='744930'>To Review, for a process to proceed spontaneously, the total
  entropy change for a system and</span> <span m='751760'>its surroundings must be
  positive. Entropy measures the number of possible ways energy</span> <span m='757070'>can
  be distributed in a system of molecules. A microstate is an instantaneous catalog
  that</span> <span m='763920'>describes the energy of each molecule in a system.
  Because molecules are constantly interacting</span> <span m='769870'>and exchanging
  energy, this description constantly needs to be revised. A given system has a</span>
  <span m='776950'>large number of possible microstates. As we saw with the Boltzmann
  equation, entropy is</span> <span m='783060'>proportional to the number of microstates.</span>
  </p>
type: course
uid: dc339cdfe5746110705e7a382b8b5cc5

---
None